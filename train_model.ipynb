{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n",
      "Model on CUDA? True\n"
     ]
    }
   ],
   "source": [
    "from baseline_cnn import *\n",
    "from baseline_cnn import BasicCNN\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import pathlib\n",
    "from evaluation import Evaluation\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Setup: initialize the hyperparameters/variables\n",
    "num_epochs = 1           # Number of full passes through the dataset\n",
    "batch_size = 32          # Number of samples in each minibatch\n",
    "learning_rate = 0.001  \n",
    "seed = np.random.seed(1) # Seed the random number generator for reproducibility\n",
    "p_val = 0.1              # Percent of the overall dataset to reserve for validation\n",
    "p_test = 0.2             # Percent of the overall dataset to reserve for testing\n",
    "\n",
    "\n",
    "#TODO: Convert to Tensor - you can later add other transformations, such as Scaling here\n",
    "transform = transforms.Compose([transforms.Resize(512),transforms.ToTensor()])\n",
    "\n",
    "\n",
    "\n",
    "# Check if your system supports CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")\n",
    "\n",
    "# Setup the training, validation, and testing dataloaders\n",
    "train_loader, val_loader, test_loader = create_split_loaders(batch_size, seed, transform=transform, \n",
    "                                                             p_val=p_val, p_test=p_test,\n",
    "                                                             shuffle=True, show_sample=False, \n",
    "                                                             extras=extras)\n",
    "\n",
    "# Instantiate a BasicCNN to run on the GPU or CPU based on CUDA support\n",
    "model = BasicCNN()\n",
    "model = model.to(computing_device)\n",
    "print(\"Model on CUDA?\", next(model.parameters()).is_cuda)\n",
    "\n",
    "#TODO: Define the loss criterion and instantiate the gradient descent optimizer\n",
    "#criterion = nn.MultiLabelSoftMarginLoss() #TODO - loss criteria are defined in the torch.nn package\n",
    "criterion = nn.BCELoss()\n",
    "#TODO: Instantiate the gradient descent optimizer - use Adam optimizer with default parameters\n",
    "optimizer = optim.Adam(model.parameters()) #TODO - optimizers are defined in the torch.optim package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicCNN(\n",
      "  (conv1): Conv2d(1, 12, kernel_size=(8, 8), stride=(1, 1))\n",
      "  (conv1_normed): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(12, 10, kernel_size=(8, 8), stride=(1, 1))\n",
      "  (conv2_normed): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(10, 8, kernel_size=(6, 6), stride=(1, 1))\n",
      "  (conv3_normed): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1928648, out_features=128, bias=True)\n",
      "  (fc1_normed): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=128, out_features=14, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up folder for model saving\n",
    "model_path = '{}/models/baseline/{}/'.format(os.getcwd(), time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "model_pathlib = pathlib.Path(model_path)\n",
    "if not model_pathlib.exists():\n",
    "    pathlib.Path(model_pathlib).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#save loss in files for futher usage.\n",
    "loss_path = '{}/losses/baseline/{}/'.format(os.getcwd(), time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "loss_pathlib = pathlib.Path(loss_path)\n",
    "if not loss_pathlib.exists():\n",
    "    pathlib.Path(loss_pathlib).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val 0 tensor(0.6937, device='cuda:0')\n",
      "Epoch 1, average minibatch 0 loss: 0.014\n",
      "val 50 tensor(0.2163, device='cuda:0')\n",
      "Epoch 1, average minibatch 50 loss: 0.379\n",
      "val 100 tensor(0.1869, device='cuda:0')\n",
      "Epoch 1, average minibatch 100 loss: 0.205\n",
      "val 150 tensor(0.1831, device='cuda:0')\n",
      "Epoch 1, average minibatch 150 loss: 0.187\n",
      "val 200 tensor(0.1824, device='cuda:0')\n",
      "Epoch 1, average minibatch 200 loss: 0.180\n",
      "val 250 tensor(0.1819, device='cuda:0')\n",
      "Epoch 1, average minibatch 250 loss: 0.192\n",
      "val 300 tensor(0.1815, device='cuda:0')\n",
      "Epoch 1, average minibatch 300 loss: 0.184\n",
      "val 350 tensor(0.1816, device='cuda:0')\n",
      "Epoch 1, average minibatch 350 loss: 0.178\n",
      "val 400 tensor(0.1810, device='cuda:0')\n",
      "Epoch 1, average minibatch 400 loss: 0.189\n",
      "val 450 tensor(0.1812, device='cuda:0')\n",
      "Epoch 1, average minibatch 450 loss: 0.191\n",
      "val 500 tensor(0.1800, device='cuda:0')\n",
      "Epoch 1, average minibatch 500 loss: 0.186\n",
      "val 550 tensor(0.1805, device='cuda:0')\n",
      "Epoch 1, average minibatch 550 loss: 0.188\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7079413ee22d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Get the next minibatch of images, labels for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mminibatch_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#         if minibatch_count == 100:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#             break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMP_STATUS_CHECK_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Track the loss across training\n",
    "total_loss = []\n",
    "avg_minibatch_loss = []\n",
    "loss_val_list = []\n",
    "loss_val_min = float('inf')\n",
    "N = 50\n",
    "# Begin training procedure\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    \n",
    "    N_minibatch_loss = 0.0\n",
    "    \n",
    "\n",
    "    # Get the next minibatch of images, labels for training\n",
    "    for minibatch_count, (images, labels) in enumerate(train_loader, 0):\n",
    "#         if minibatch_count == 100:\n",
    "#             break\n",
    "        # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "        images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "\n",
    "        # Zero out the stored gradient (buffer) from the previous iteration\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform the forward pass through the network and compute the loss\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "#         print('training',minibatch_count,loss)\n",
    "        # Automagically compute the gradients and backpropagate the loss through the network\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Add this iteration's loss to the total_loss\n",
    "        total_loss.append(loss.item())\n",
    "        N_minibatch_loss += loss\n",
    "        \n",
    "        #TODO: Implement validation\n",
    "        if minibatch_count % N == 0:\n",
    "            #switch to evaluate mode\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                loss_val = 0\n",
    "                for count_val, (images_val, labels_val) in enumerate(val_loader):\n",
    "#                     if count_val ==10:\n",
    "#                         break\n",
    "                    images_val, labels_val = images_val.to(computing_device), labels_val.to(computing_device)\n",
    "                    outputs_val = model(images_val)\n",
    "                    loss_val += criterion(outputs_val, labels_val)\n",
    "#                     print('val',count_val, (loss_val/(count_val+1)))\n",
    "                loss_val /= count_val\n",
    "                print('val',minibatch_count,loss_val)\n",
    "                loss_val_list.append(loss_val.item())\n",
    "                if loss_val < loss_val_min:\n",
    "                    model_name = \"epoch_{}-batch_{}-loss_{}-{}.pt\".format(epoch, minibatch_count, loss_val, time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "                    torch.save(model.state_dict(), os.path.join(model_path, model_name))\n",
    "                    loss_val_min = loss_val\n",
    "                    \n",
    "        if minibatch_count % N == 0:    \n",
    "            \n",
    "            # Print the loss averaged over the last N mini-batches    \n",
    "            N_minibatch_loss /= N\n",
    "            print('Epoch %d, average minibatch %d loss: %.3f' %\n",
    "                (epoch + 1, minibatch_count, N_minibatch_loss))\n",
    "            \n",
    "            # Add the averaged loss over N minibatches and reset the counter\n",
    "            avg_minibatch_loss.append(N_minibatch_loss.item())\n",
    "            N_minibatch_loss = 0.0\n",
    "            \n",
    "        prefix = 'baseline_loss_'\n",
    "        with open(os.path.join(loss_path, prefix+\"training.txt\"), \"w\") as f:\n",
    "            for s in total_loss:\n",
    "                f.write(str(s) +\"\\n\")\n",
    "\n",
    "        with open(os.path.join(loss_path, prefix+\"training_ave.txt\"), \"w\") as f:\n",
    "            for s in avg_minibatch_loss:\n",
    "                f.write(str(s) +\"\\n\")\n",
    "\n",
    "        with open(os.path.join(loss_path, prefix+\"val.txt\"), \"w\") as f:\n",
    "            for s in loss_val_list:\n",
    "                f.write(str(s) +\"\\n\")\n",
    "            \n",
    "    print(\"Finished\", epoch + 1, \"epochs of training\")\n",
    "print(\"Training complete after\", epoch, \"epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/datasets/home/home-02/60/960/kshi/PA3/models/baseline/20190214-192159/epoch_0-batch_500-loss_0.1799965351819992-20190214-202710.pt'\n",
    "model_test = BasicCNN()\n",
    "model_test = model_test.to(computing_device)\n",
    "model_test.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all = []\n",
    "predictions_all = []\n",
    "for data in test_loader:\n",
    "    images, labels = data\n",
    "    \n",
    "    images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "    labels_all.append(labels)\n",
    "    output = model_test(images)\n",
    "    predictions = output > 0.5\n",
    "    predictions_all.append(predictions)\n",
    "\n",
    "labels = torch.cat(labels_all,0)\n",
    "predctions = torch.cat(predictions_all,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP [795.0, 180.0, 1328.0, 2734.0, 328.0, 275.0, 179.0, 367.0, 579.0, 357.0, 350.0, 70.0, 9.0, 8.0]\n",
      "FP [6621.0, 6061.0, 6822.0, 11836.0, 6017.0, 4390.0, 12501.0, 5218.0, 11234.0, 15382.0, 15296.0, 7701.0, 351.0, 8065.0]\n",
      "TN [11584.0, 13628.0, 10955.0, 4794.0, 13102.0, 14680.0, 7432.0, 14010.0, 8149.0, 4406.0, 4440.0, 12155.0, 19201.0, 12078.0]\n",
      "FN [1181.0, 312.0, 1076.0, 817.0, 734.0, 836.0, 69.0, 586.0, 219.0, 36.0, 95.0, 255.0, 620.0, 30.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<evaluation.Evaluation at 0x7f4c305abcc0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluation(predctions.float(), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP [795.0, 180.0, 1328.0, 2734.0, 328.0, 275.0, 179.0, 367.0, 579.0, 357.0, 350.0, 70.0, 9.0, 8.0]\n",
      "FP [6621.0, 6061.0, 6822.0, 11836.0, 6017.0, 4390.0, 12501.0, 5218.0, 11234.0, 15382.0, 15296.0, 7701.0, 351.0, 8065.0]\n",
      "TN [11584.0, 13628.0, 10955.0, 4794.0, 13102.0, 14680.0, 7432.0, 14010.0, 8149.0, 4406.0, 4440.0, 12155.0, 19201.0, 12078.0]\n",
      "FN [1181.0, 312.0, 1076.0, 817.0, 734.0, 836.0, 69.0, 586.0, 219.0, 36.0, 95.0, 255.0, 620.0, 30.0]\n",
      "tensor([0.6134, 0.6842, 0.6086, 0.3730, 0.6655, 0.7410, 0.3771, 0.7124, 0.4325,\n",
      "        0.2360, 0.2374, 0.6058, 0.9519, 0.5989], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5598, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "eval = Evaluation(predctions.float(), labels)\n",
    "print(eval.accuracy())\n",
    "print(eval.accuracy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1072, 0.0288, 0.1629, 0.1876, 0.0517, 0.0589, 0.0141, 0.0657, 0.0490,\n",
       "        0.0227, 0.0224, 0.0090, 0.0250, 0.0010], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4023, 0.3659, 0.5524, 0.7699, 0.3089, 0.2475, 0.7218, 0.3851, 0.7256,\n",
       "        0.9084, 0.7865, 0.2154, 0.0143, 0.2105], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
